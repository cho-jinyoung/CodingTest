## lec07-1. Application&tips: Learning rate, data preprocessing, overfitting
### Gradient descent
- Large learning rate -overshooting
- Small learning rate -takes too long, stops at local minimum
*=> Try several learning rates → 보통 0.01로 시작*  
*→ 발산하면 값을 더 작게, 너무 작게 움직이면 값을 더 크게 수정하며 cost function출력 확인*
### Data(x) preprocessing for gradient descent  
![image](https://user-images.githubusercontent.com/54131109/75787336-ea4d1d80-5da9-11ea-8534-fa765769e1dd.png)  
- zero-centered data → 데이터의 중심이 0으로 가도록
- normalized data → 데이터들이 정해진 범위내에 들어가도록
- standardization (python코드)
![image](https://user-images.githubusercontent.com/54131109/75787622-52036880-5daa-11ea-8667-feb4905317e4.png)
### overfitting
