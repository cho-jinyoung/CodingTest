## lec07-1. Application&tips: Learning rate, data preprocessing, overfitting
### Learning rate
- Large learning rate -overshooting
- Small learning rate -takes too long, stops at local minimum
**=> Try several learning rates → 보통 0.01로 시작 → 발산하면 값을 더 작게, 너무 작게 움직이면 값을 더 크게 수정하며 cost function출력 확인**
### Data(x) preprocessing for gradient descent  
![image](https://user-images.githubusercontent.com/54131109/75787336-ea4d1d80-5da9-11ea-8534-fa765769e1dd.png)  
- zero-centered data → 데이터의 중심이 0으로 가도록
- normalized data → 데이터들이 정해진 범위내에 들어가도록
- standardization (python코드)
![image](https://user-images.githubusercontent.com/54131109/75787622-52036880-5daa-11ea-8667-feb4905317e4.png)  
### overfitting
- 테스트 데이터에는 잘 맞지만 실제 데이터에는 안맞는 경우가 있음  
![image](https://user-images.githubusercontent.com/54131109/75788204-3e0c3680-5dab-11ea-9c28-20ba3da61b81.png)  
 → model1이 더 좋은 모델, model2는 저 데이터에만 맞춰진 모델  
**=> more training data, reduce the number of features, Regularization**  
#### Regularization(일반화)
- cost함수에 각 엘리먼트의 값의 합(=regularization)을 추가
```python
# regularization
l2reg = 0.001 * tf.reduce_sum(tf.square(W))
```
## lab.07-1. training/test dataset, learning rate, normalization  
```python
import tensorflow as tf
tf.set_random_seed(777)  # for reproducibility

#training dataset
x_data = [[1, 2, 1], [1, 3, 2], [1, 3, 4], [1, 5, 5], [1, 7, 5], [1, 2, 5], [1, 6, 6], [1, 7, 7]]
y_data = [[0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 1, 0], [1, 0, 0], [1, 0, 0]]

#test dataset
x_test = [[2, 1, 1], [3, 1, 2], [3, 3, 4]]
y_test = [[0, 0, 1], [0, 0, 1], [0, 0, 1]]

X = tf.placeholder("float", [None, 3])
Y = tf.placeholder("float", [None, 3])
W = tf.Variable(tf.random_normal([3, 3]))
b = tf.Variable(tf.random_normal([3]))

# tf.nn.softmax computes softmax activations
# softmax = exp(logits) / reduce_sum(exp(logits), dim)
hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)

# Cross entropy cost/loss
cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))
# Try to change learning_rate to small numbers
optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)

# Correct prediction Test model 값을 예측하고 맞는지 아닌지 확인
prediction = tf.argmax(hypothesis, 1)
is_correct = tf.equal(prediction, tf.argmax(Y, 1))
accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))

# Launch graph
with tf.Session() as sess:
    # Initialize TensorFlow variables
    sess.run(tf.global_variables_initializer())
    for step in range(201):
        cost_val, W_val, _ = sess.run([cost, W, optimizer], feed_dict={X: x_data, Y: y_data})
        print(step, cost_val, W_val)
    # predict
    print("Prediction:", sess.run(prediction, feed_dict={X: x_test}))
    # Calculate the accuracy
    print("Accuracy: ", sess.run(accuracy, feed_dict={X: x_test, Y: y_test}))
```
![image](https://user-images.githubusercontent.com/54131109/75792170-ef619b00-5db0-11ea-843d-7a89ea917aa9.png)  
**Prediction, Accuracy값은 test data를 넣었을 때의 값(맨 앞의 숫자가 step)**  
- learning rate: NaN  
![image](https://user-images.githubusercontent.com/54131109/75791829-7b26f780-5db0-11ea-95f7-9b87a7c3ede2.png)  
```python
# Cross entropy cost/loss
cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))
# learning_rate의 값만 크게 변경
optimizer = tf.train.GradientDescentOptimizer(learning_rate=1.5).minimize(cost)
```
**cost의 결과가 [nan nan nan]으로 나올 경우 learning_rate이 크다고 의심  
step이 반복되는데도 cost의 값이 같은 경우 learning_rate이 너무 작아 local minimam에 빠졌거나 거의 이동되지 않는 것** 
- - - - - - - - - - -
## lec07-2. Application&tips: Learning and test data sets
![image](https://user-images.githubusercontent.com/54131109/75969830-da9d1880-5f12-11ea-9b42-a9ba4a980788.png)  
validation = 모의테스트  
- online learning: 많은 데이터를 나눠서 학습하는데 앞서 학습한 내용이 모델에 남아있는 채로 다음 데이터를 학습시키는 방식
## lab07-2. Meet MNIST Dataset
### MNIST Dataset
```python
from tensorflow.examples.tutorials.mnist import input_data
# Check out https://www.tensorflow.org/get_started/mnist/beginners for
# more information about the mnist dataset
# one-hot=true 따로 one-hot형식으로 만들지 않아도 읽어올 때 y값을 one-hot으로 읽어옴
mnist = input_data.read_data_sets("MNIST_data/", one_hot=True)

# MNIST data image of shape 28 * 28 = 784  x = 784개, none=n개
X = tf.placeholder(tf.float32, [None, 784])
# 0 - 9 digits recognition = 10 classes  y = 0~9 10개(one-hot encoding) 10개의 출력
Y = tf.placeholder(tf.float32, [None, nb_classes])

W = tf.Variable(tf.random_normal([784, nb_classes]))
b = tf.Variable(tf.random_normal([nb_classes]))

# Hypothesis (using softmax)
hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)
# tf.reduce_mean=평균, tf.reduce_sum=합
cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))
train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)

# Test model
is_correct = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))
# Calculate accuracy
accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))

# parameters
# epoch = 데이터 셋 전체를 한번 학습시킨 것
num_epochs = 15
# batch_size = 데이터 셋이 너무 많은 경우 나눠서 학습시킬건데 한번에 몇개씩 할 것인지
batch_size = 100
# 전체 데이터의 개수 / 배치크기 = 몇번 돌면 전체 데이터 셋을 도는지(=1epoch)
num_iterations = int(mnist.train.num_examples / batch_size)

with tf.Session() as sess:
    # Initialize TensorFlow variables
    sess.run(tf.global_variables_initializer())
    # Training cycle
    for epoch in range(num_epochs):
        avg_cost = 0

        for i in range(num_iterations):
            batch_xs, batch_ys = mnist.train.next_batch(batch_size)
            _, cost_val = sess.run([train, cost], feed_dict={X: batch_xs, Y: batch_ys})
            avg_cost += cost_val / num_iterations
        print("Epoch: {:04d}, Cost: {:.9f}".format(epoch + 1, avg_cost))

    # Test the model using test sets
    # 학습할 때 사용했던 training data가 아닌 test데이터를 사용하여 accuracy평가
    # sess.run() = accuracy.eval()
    print("Accuracy: ", accuracy.eval(session=sess, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))
```
```python
# 실제 적용
import matplotlib.pyplot as plt
import random

# random한 숫자를 하나 읽어옴
r = random.randint(0, mnist.test.num_examples - 1)
# tf.argmax=one-hot으로 된 랜덤한 숫자(mnist.test.labels)가 무엇인지
print("Label:", sess.run(tf.argmax(mnist.test.labels[r:r+1], 1)))
# 예측을 위해 hypothesis실행
print("Prediction:", sess.run(tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r+1]}))

# 테스트 한 이미지 출력
plt.imshow(mnist.test.images[r:r+1].reshape(28,28),cmap='Greys', interpolation='nearest')
plt.show()

```
